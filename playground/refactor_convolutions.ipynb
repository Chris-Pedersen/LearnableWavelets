{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e4ce5a",
   "metadata": {},
   "source": [
    "## Refactor wavelet initialisation\n",
    "\n",
    "Notebook to play around with classes and objects during the great Kymatio refactor of 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc56f865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrisp/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sn_camels.models.models_factory import baseModelFactory, topModelFactory\n",
    "from sn_camels.models.sn_hybrid_models import sn_HybridModel\n",
    "from sn_camels.models.camels_models import get_architecture \n",
    "from sn_camels.camels.camels_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a065447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Not Available\n"
     ]
    }
   ],
   "source": [
    "## Check if CUDA available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Available\")\n",
    "    device = torch.device('cuda')\n",
    "    use_cuda=True\n",
    "else:\n",
    "    print('CUDA Not Available')\n",
    "    device = torch.device('cpu')\n",
    "    use_cuda=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "221b9d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "camels_path=\"/home/chrisp/Data/CAMELs/\"\n",
    "fparams    = camels_path+\"/params_IllustrisTNG.txt\"\n",
    "fmaps      = [\n",
    "              camels_path+\"maps_Mtot.npy\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82da8d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 channels\n",
      "Reading data...\n",
      "6.054e+09 < F(all|orig) < 2.176e+15\n",
      "9.782 < F(all|resc)  < 15.338\n",
      "-2.696 < F(all|norm) < 8.631\n",
      "Channel 0 contains 7200 maps\n",
      "-2.696 < F < 8.631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## dataloader options\n",
    "seed=123\n",
    "\n",
    "batch_size=10\n",
    "splits=1\n",
    "fmaps_norm=[None]\n",
    "num_workers=1\n",
    "rot_flip_in_mem=True\n",
    "channels=1\n",
    "features=1\n",
    "\n",
    "train_loader = create_dataset_multifield('train', seed, fmaps, fparams, batch_size, splits, fmaps_norm,\n",
    "                                                 num_workers=num_workers, rot_flip_in_mem=rot_flip_in_mem, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0bfe1f0-c80e-466c-b316-658f80ca22eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n",
      "(128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrisp/.local/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/chrisp/.local/lib/python3.8/site-packages/sn_camels-0.0.1-py3.8.egg/sn_camels/scattering/create_filters.py:283: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2981.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sn_HybridModel(\n",
       "  (scatteringBase): sn_ScatteringBase()\n",
       "  (top): sn_LinearLayer(\n",
       "    (fc1): Linear(in_features=73, out_features=1, bias=True)\n",
       "    (bn0): BatchNorm1d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatteringBase = baseModelFactory( #creat scattering base model\n",
    "    architecture='scattering',\n",
    "    J=2,\n",
    "    N=256,\n",
    "    M=256,\n",
    "    channels=channels,\n",
    "    max_order=2,\n",
    "    initialization=\"Random\",\n",
    "    seed=234,\n",
    "    learnable=True,\n",
    "    lr_orientation=0.03,\n",
    "    lr_scattering=0.03,\n",
    "    skip=True,\n",
    "    split_filters=True,\n",
    "    filter_video=False,\n",
    "    subsample=4,\n",
    "    device=device,\n",
    "    use_cuda=use_cuda,\n",
    "    plot=False\n",
    ")\n",
    "\n",
    "## Now create a network to follow the scattering layers\n",
    "## can be MLP, linear, or cnn at the moment\n",
    "## (as in https://github.com/bentherien/ParametricScatteringNetworks/ )\n",
    "top = topModelFactory( #create cnn, mlp, linear_layer, or other\n",
    "    base=scatteringBase,\n",
    "    architecture=\"linear_layer\",\n",
    "    num_classes=features,\n",
    "    width=3,\n",
    "    average=True,\n",
    "    use_cuda=use_cuda\n",
    ")\n",
    "\n",
    "hybridModel = sn_HybridModel(scatteringBase=scatteringBase, top=top, use_cuda=use_cuda)\n",
    "model=hybridModel\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9622254-5506-4f23-a597-2d83f6497463",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(iter(train_loader))\n",
    "model.to(device=device)\n",
    "x=x.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa88572e-d46e-44f2-b10e-46a9e14aacfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_convolutions(x, backend, J, phi, wavelets, max_order,\n",
    "        split_filters, subsample):\n",
    "    \"\"\" Function to take an input image and perform a series of scattering\n",
    "    convolutions.\"\"\"\n",
    "    subsample_fourier = backend.subsample_fourier\n",
    "    modulus = backend.modulus\n",
    "    fft = backend.fft\n",
    "    cdgmm = backend.cdgmm\n",
    "    concatenate = backend.concatenate\n",
    "    \n",
    "    wavelets = wavelets.real.contiguous().unsqueeze(3)\n",
    "\n",
    "    # Define lists for output.\n",
    "    out_S_0, out_S_1, out_S_2 = [], [], []\n",
    "    \n",
    "    ## Map to complex\n",
    "    complex_maps = x.new_zeros(x.shape + (2,))\n",
    "    complex_maps[..., 0] = x\n",
    "\n",
    "    U_0_c = fft(complex_maps, 'C2C')\n",
    "    print(U_0_c.shape)\n",
    "    \n",
    "\n",
    "    # First low pass filter\n",
    "    U_1_c = cdgmm(U_0_c, phi[0])\n",
    "    U_1_c = subsample_fourier(U_1_c, k=subsample)\n",
    "\n",
    "\n",
    "    S_0 = fft(U_1_c, 'C2R', inverse=True)\n",
    "\n",
    "    out_S_0.append({'coef': S_0})\n",
    "\n",
    "    if split_filters:\n",
    "        for n1 in range(int(len(wavelets)/2)):\n",
    "\n",
    "            ## Wavelet convolution\n",
    "            \n",
    "            U_1_c = cdgmm(U_0_c, wavelets[n1])\n",
    "\n",
    "            U_1_c = fft(U_1_c, 'C2C', inverse=True)\n",
    "            U_1_c = modulus(U_1_c)\n",
    "            U_1_c = fft(U_1_c, 'C2C')\n",
    "\n",
    "            ## Second low pass filter\n",
    "            S_1_c = cdgmm(U_1_c, phi[0])\n",
    "            S_1_c = subsample_fourier(S_1_c, k=subsample)\n",
    "\n",
    "            S_1_r = fft(S_1_c, 'C2R', inverse=True)\n",
    "\n",
    "            out_S_1.append({'coef': S_1_r})\n",
    "\n",
    "            if max_order < 2:\n",
    "                continue\n",
    "            for n2 in range(int(len(psi)/2),len(psi)):\n",
    "                \n",
    "\n",
    "                U_2_c = cdgmm(U_1_c, wavelets[n2])\n",
    "                U_2_c = fft(U_2_c, 'C2C', inverse=True)\n",
    "                U_2_c = modulus(U_2_c)\n",
    "                U_2_c = fft(U_2_c, 'C2C')\n",
    "\n",
    "                ## Low pass filter\n",
    "                S_2_c = cdgmm(U_2_c, phi[0])\n",
    "                \n",
    "                S_2_c = subsample_fourier(S_2_c, k=subsample)\n",
    "\n",
    "                S_2_r = fft(S_2_c, 'C2R', inverse=True)\n",
    "                \n",
    "\n",
    "                out_S_2.append({'coef': S_2_r})\n",
    "    else:\n",
    "        for n1 in range(len(wavelets)):\n",
    "            ## Wavelet convolution\n",
    "            U_1_c = cdgmm(U_0_c, wavelets[n1])\n",
    "\n",
    "            U_1_c = fft(U_1_c, 'C2C', inverse=True)\n",
    "            U_1_c = modulus(U_1_c)\n",
    "            U_1_c = fft(U_1_c, 'C2C')\n",
    "\n",
    "            ## Second low pass filter\n",
    "            S_1_c = cdgmm(U_1_c, phi[0])\n",
    "            S_1_c = subsample_fourier(S_1_c, k=subsample)\n",
    "\n",
    "            S_1_r = fft(S_1_c, 'C2R', inverse=True)\n",
    "\n",
    "            out_S_1.append({'coef': S_1_r})\n",
    "\n",
    "            if max_order < 2:\n",
    "                continue\n",
    "            for n2 in range(len(wavelets)):\n",
    "                \n",
    "                U_2_c = cdgmm(U_1_c, wavelets[n2])\n",
    "                U_2_c = fft(U_2_c, 'C2C', inverse=True)\n",
    "                U_2_c = modulus(U_2_c)\n",
    "                U_2_c = fft(U_2_c, 'C2C')\n",
    "\n",
    "                ## Low pass filter\n",
    "                S_2_c = cdgmm(U_2_c, phi[0])\n",
    "                S_2_c = subsample_fourier(S_2_c, k=subsample)\n",
    "                S_2_r = fft(S_2_c, 'C2R', inverse=True)\n",
    "                \n",
    "\n",
    "                out_S_2.append({'coef': S_2_r})\n",
    "\n",
    "    out_S = []\n",
    "    out_S.extend(out_S_0)\n",
    "    out_S.extend(out_S_1)\n",
    "    out_S.extend(out_S_2)\n",
    "\n",
    "    out_S = concatenate([x['coef'] for x in out_S])\n",
    "\n",
    "    return out_S\n",
    "\n",
    "def convolve_fields(input, backend, J, phi, wavelets, max_order, split_filters, subsample):\n",
    "    \"\"\"  \n",
    "        Wrapper function for a loop that will convovle each wavelet with the input fields\n",
    "\n",
    "        Parameters:\n",
    "            input      -- input data\n",
    "            psi        -- dictionnary of filters that is used in the kymatio code\n",
    "            split_filters -- split first and second order filters\n",
    "        Returns:\n",
    "            S -- Fields after being convolved with wavelets\n",
    "    \"\"\"\n",
    "\n",
    "    batch_shape = input.shape[:-2]\n",
    "    signal_shape = input.shape[-2:]\n",
    "\n",
    "    input = input.reshape((-1,) + signal_shape)\n",
    "\n",
    "    S = do_convolutions(input, backend, J, phi, wavelets,\n",
    "                        max_order, split_filters, subsample)\n",
    "\n",
    "    ## S will always be a numpy array\n",
    "    scattering_shape = S.shape[-3:]\n",
    "    S = S.reshape(batch_shape + scattering_shape)\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "264f6db2-e753-4c05-921b-94afb2d8bc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 256, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bfa2dd0-2ad3-497d-80ed-3b9a1431800f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 256, 256, 2])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The input should be complex (i.e. last dimension is 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconvolve_fields\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscatteringBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscatteringBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscatteringBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscatteringBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwavelets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mscatteringBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscatteringBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_filters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscatteringBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubsample\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mconvolve_fields\u001b[0;34m(input, backend, J, phi, wavelets, max_order, split_filters, subsample)\u001b[0m\n\u001b[1;32m    127\u001b[0m signal_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m+\u001b[39m signal_shape)\n\u001b[0;32m--> 131\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mdo_convolutions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavelets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmax_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_filters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m## S will always be a numpy array\u001b[39;00m\n\u001b[1;32m    135\u001b[0m scattering_shape \u001b[38;5;241m=\u001b[39m S\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:]\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mdo_convolutions\u001b[0;34m(x, backend, J, phi, wavelets, max_order, split_filters, subsample)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(U_0_c\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# First low pass filter\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m U_1_c \u001b[38;5;241m=\u001b[39m \u001b[43mcdgmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mU_0_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m U_1_c \u001b[38;5;241m=\u001b[39m subsample_fourier(U_1_c, k\u001b[38;5;241m=\u001b[39msubsample)\n\u001b[1;32m     29\u001b[0m S_0 \u001b[38;5;241m=\u001b[39m fft(U_1_c, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC2R\u001b[39m\u001b[38;5;124m'\u001b[39m, inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sn_camels-0.0.1-py3.8.egg/sn_camels/scattering/torch_backend.py:240\u001b[0m, in \u001b[0;36mcdgmm\u001b[0;34m(A, B, inplace)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m\"\"\"Complex pointwise multiplication.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    Complex pointwise multiplication between (batched) tensor A and tensor B.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m        C[b, c, m, n, :] = A[b, c, m, n, :] * B[m, n, :].\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_real(B):\n\u001b[0;32m--> 240\u001b[0m     \u001b[43mtype_checks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m B\u001b[38;5;241m.\u001b[39mis_contiguous():\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sn_camels-0.0.1-py3.8.egg/sn_camels/scattering/torch_backend.py:207\u001b[0m, in \u001b[0;36mtype_checks\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtype_checks\u001b[39m(x):\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_complex(x):\n\u001b[0;32m--> 207\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe input should be complex (i.e. last dimension is 2).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mis_contiguous():\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensors must be contiguous.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: The input should be complex (i.e. last dimension is 2)."
     ]
    }
   ],
   "source": [
    "convolve_fields(x, scatteringBase.backend, scatteringBase.J, scatteringBase.phi, scatteringBase.wavelets,\n",
    "                                    scatteringBase.max_order, scatteringBase.split_filters,scatteringBase.subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbade4ab-5d68-43d4-b717-50f9bb1f9b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
